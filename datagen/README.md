## Overview
This is an data generator implemented using faker.
* Input: Several JSON file to be mocked and field value under `./data/target/`.
* Output: Generated JSON list data set in json under `./data/output/`



## Usage
Run sample:
``

Provide paired JSON file under `./data/output/`:
Format JSON file `XXX.json`, relevant updating field value `XXX_field.json` ( `_field` will be used to search for file).

Notice:
User provided value in `XXX_field.json` needs to be within a JSON list,
Time value to be generated by faker either be `RAND_TIME_MILLI` or `RAND_TIME_ISO8601`(Currently only support these, mapped to faker time provider).

Go under `./src/` directory and run `python3 ./main.py` or `python ./main.py` to generate data.
In `main.py`:
`target_files` defines which files will be mock, `XXX.json`
`amount` defines how many data will be generated

Output will be under `./data/output/`:
A JSON file named the same as `XXX.json` with a JSON object inside:
`XXX_generated`:[ list of `amount` generaed data ]



## Compatibility
* Python: 3.9.6
* Faker : 19.4.0, faker requires python 3.7 and above
* Kafka : confluent_kafka, jsonschema, requests

## TBA
* Format of `event_tags` and `RAND_TIME_ISO8601` needs rework
* More reasonable value, generate time stamp field in a given time period
* Relative directory while running script
* Go to kafka
    - Configure data schema
    - Add DAO object for data schema object
    - Add logging (needed in kafka_consumer.py)
* Automatic generate data and produce to topic
* Maybe restructure the way sending event, currently is sequently sending event into topic (needed in kafka_producer.py)

* Count create, close event filter
* 